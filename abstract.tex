% LaTeX template file for a UC Davis Mathematics / Physics Ph.D. Dissertation
% The UC Davis Dissertation Formatting Requirements can be found at
% http://www.gradstudies.ucdavis.edu/students/filing.html
\documentclass[ucdthesis.tex]{subfiles}
    
\begin{document}
    % The following commands produce page numbering at the bottom
    % center using roman numerals per UC Davis requirements for the
    % front matter of the dissertation:
    % \pagenumbering{roman}
    % \pagestyle{plain}

    % The following command produces double-spaced lines for the
    % remainder of the document:
    \doublespacing
		\section*{Abstract} 
		\addcontentsline{toc}{chapter}{Abstract}

		% (ARGUE THE SIGNIFICANCE OF STUDYING DARK MATTER IN GENERAL)
		{\it ``Mass tells spacetime how to bend, spacetime tells mass how to move".}
		This famous quote by physicist John Archibald Wheeler succinctly summarizes General
		Relativity,  the most successful theory that describes our universe
		at large scale. Most of the mass that general relativity describes,
		namely Dark Matter (DM), however, remains a mystery.  
		We have solid evidence of the existence of DM from various
		observations, e.g.	galaxy rotation
		curves, the primordial element ratios for nucleosynthesis, the Cosmic
		Microwave Background (CMB) and galaxy cluster mergers etc.
		We still need to find out the particle nature of DM,  
		how DM particles interact with different particles, and its role in the
		evolution of the universe. Completing this knowledge gap would improve or 
		revolutionalize our established cosmological model,
		the Lambda Cold-Dark Matter	($\Lambda$CDM) model, 
		and give directions to theories beyond the standard particle
		physics model. 

		% need more passion and conviction to argue WHY the study of DM needs a
		% probabilistic approach 
			This work attempts to study DM by examining and
		extending existing modeling approaches of DM and its visible tracers in a
		probabilistic way. The single verified form of 
		DM interaction is gravitational. Before the mankind can build a sensitive 
		enough detector to detect gravitational waves generated by DM movements, the 
		only way to infer the properties of DM is through visible tracers. Most of 
		these indirect detections	either have low signal-to-noise, sparse coverage, 
		or depend on missing
		variables. This introduces additional
		modeling choices and uncertainties. A probabilistic approach allows us to
		handle the uncertainties appropriately and marginalize any missing variables 
		according to the assumed properties of DM and visible tracers respectively. 	
		
		There are two recurring types of visible tracers that 
		my work uses: The first type of tracers are galaxies and observables in the 
		 overdense regions of DM. These tracers allow 
		us to infer the macroscopic dynamical properties of DM that we want to study. The
		second type of tracers, on the hand, are in the background, i.e.
		further away than the foreground dark matter, from us observers. The
		gravity of DM can bend spacetime such that the path of light traveling in 
		the vicinity would also curve, leaving distortions in the galaxy images. 
		The gravitational distortion of the images 
		of the background galaxies is also known as gravitational lensing. In the
		introduction (first chapter) of this thesis, I will lay out the technical
		history, terminology and the reasons behind choosing the various data sets
		and analysis methods for my thesis work. 
		
			In chapter two, I will present the study based on the observational data 
			of El Gordo, one of the most massive, most ancient, merging galaxy clusters. 
		Under the extreme collision speeds during a merger of a galaxy cluster, 
		it is more probable for DM particles in the cluster to manifest effects of
		self-interaction. Thus, if DM particles can interact with one another, 		
		the large-scale distribution of DM may lag behind
		its collisionless galaxy-counterparts along the direction of motion. This
		lag is also known as the galaxy-DM offset, with one caveat. The long duration 
		(millions of years) 
		of a merger means that we cannot detect the
		direction of motions of the components directly to confirm the offset as
		a lag. My work on El Gordo was the first show a quantitative method of estimating
		how likely the DM components of El Gordo to be moving in a certain
		direction.	This study was made possible by utilizing informative
		observables in various wavelengths, including a pair of radio shockwaves on
		the outer skirt of the cluster, enhanced X-ray emissivity and deficiency of the
		Sunyaev-Zel'Dovich effect for the infra-red observations.
		These comprehensive set of observables allowed us to formulate 
		probabilistic constraints in our Monte Carlo simulation of El Gordo.
		Furthermore, the study also brought up several questions about the modeling
		choices for comparing the DM and the member-galaxy distributions of a cluster.
		
		% two more paragraphs about each paper then provide a summary.
		To address my raised concerns from the study of El Gordo, 
		I conducted a second investigation of galaxy clusters in a cosmological
		simulation, which is described in chapter 3. The data we chose from the 
		cosmological simulation, the Illustris simulation. As this simulation
		assumes a Cold-Dark-Matter model (CDM) without requiring a self-interacting
		dark matter (SIDM) model, any offset between DM and the member galaxies in a 
		galaxy cluster provides an estimate of the variability of the galaxy-DM offset. This
		estimate provides a basis for testing whether SIDM describes reality. As
		the measured variability in this setting is non-negligible, it is more
		likely that random variation can account for the
		galaxy-DM offsets in observations, it weakens our belief that SIDM is the
		cause of the offsets. 

			The fourth chapter of my thesis builds on top of my previous experience
			with analyzing the weak lensing data for El Gordo. This time, I performed 
			the weak lensing study performed for a dataset of a much larger scale, 
			such that, galaxy
		clusters look like parts of a homogeneous and isotropic DM web. At this scale,
		it is possible to compare the spatial distribution of DM to simulations to give 
		competitive constraints on cosmological parameters. Using weak lensing
		signals for estimating cosmological parameters is also known as cosmic shear 
		inference. While I used a parametric technique to estimate the mass of El Gordo, 
		my new work has introduced a new non-parametric model using a Gaussian Process.
		A Gaussian Process is a generalization of the multivariate normal distribution 
		to higher dimensions. We can draw functional models from a Gaussian Process
		to describe our data. While the realizations are drawn from a multivariate
		normal distribution,  we can specify the parameters and the
		functional structure of the covariance matrix of the underlying 
		distribution. 
		This generative model gives us the ability to put probabilistic estimates 
		of DM density in regions without any background galaxies. 
		As I have built the lensing physics into the 
		very core of the covariance kernel matrix, we can also simultaneously infer the
		several important lensing observables given some lensed galaxy shapes. 
		More importantly, this technique relies on fewer assumptions about the
		cosmology than traditional cosmic shear analysis technique. This may reduce
		the bias towards a fiducial cosmology and lead to interesting discoveries.
		However, this new technique is not without its challenges. Computationally
		this technique requires $O(n^3)$ runtime. Despite my best attempts to
		parallelize the computation, the runtime of the algorithm takes longer for
	  generating DM mass maps than traditional approaches. My work here,
		hopefully, just marks the beginning of an alternative method for cosmic
		shear inference. Many promising approximation techniques will emerge to 
		drastically speed up the runtime of doing inference with a Gaussian Process,
		making it possible to use this method to give better cosmological constraints  
		from future sky surveys such as the Large Synoptic Sky Telescope.  

		


	  % This simulation 	
		% The Illustris simulation also provided observables that
		% are missing in telescope observations.

		% We made use of most of the widely-used point-statistic
		% for summarizing the DM and galaxy distributions in this data, 
		% such as the centroid, or the density peaks, of the spatial distributions of 
		% galaxy cluster components. Then we computed the  

	  % Apply the analytical principles for analyzing DM on even larger scales than
		% galaxy clusters. 
		




		% Probabilistic methods allow for less bias estimates and characterizes our
		% uncertainties than point estimates. 

		% Discovery: galaxy rotation curves, big bang nucleosynthesis, strong lensing
		% and weak lensing
		% Understanding Dark Matter (DM) at different length scales can bridge a gap
		% between two of the most successful physics models, the Standard Model for
		% particle physics and the Lambda Cold Dark Matter (Î›CDM) cosmological model.
       
    \newpage
    

\end{document}
